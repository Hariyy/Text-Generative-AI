{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cccfb40-763e-4ea1-b31a-16e7c065f8b1",
   "metadata": {},
   "source": [
    "# Description\n",
    "Notebook demonstrating semantic search. Documents in a corpus are loaded into memory, chunked\n",
    "and chunks are converted to vector embeddings. User queries are embedded with the same model, and the most\n",
    "similar document chunks are fetched as search results.\n",
    "\n",
    "- Image: *Data Science 3.0*\n",
    "- Assumes corpus can be held in-memory\n",
    "\n",
    "# Installations\n",
    "Don't mind the warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3be169a3-cd09-48f6-a9bf-c37a6a1913ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip --quiet\n",
    "!pip install langchain --quiet\n",
    "!pip install transformers[torch] --no-cache-dir --quiet\n",
    "!pip install sentence-transformers --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c691f1bc-496b-4204-b086-cab2dc6eb166",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "630fa167-db6b-4861-85da-43e949238de0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import logging\n",
    "import langchain\n",
    "import nltk, time\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Download punkt\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5df396-e11d-4ebe-87df-4cd3663ae10c",
   "metadata": {},
   "source": [
    "# Document Embedding\n",
    "We load, chunk, and then embed in this section with an embedding model of choice.\n",
    "\n",
    "## Loading Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd70cc96-7b3b-4db0-8e2a-840b1f153d77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Source directory\n",
    "source_dir = './data/wikipedia'\n",
    "\n",
    "# Dictionary with document full-texts\n",
    "docs = {}\n",
    "for filename in os.listdir(source_dir):\n",
    "    if os.path.isfile(filepath := os.path.join(source_dir, filename)):\n",
    "        with open(filepath, 'r') as inf:\n",
    "            docs[filename] = {'raw': inf.read()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a9aad8-54a2-4f64-b2a1-599c4afb2d61",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Select Embedding Model\n",
    "Set up a sentence embedding model to process corpus documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5abf216-3900-4e31-8240-bc73a0a9c8a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define model options and relevant configuration\n",
    "model_options = {\n",
    "    'msmarco-distilbert-base-v4': {\n",
    "        'base_repo': 'sentence-transformers',\n",
    "        'similarity': 'cosine'\n",
    "    },\n",
    "    'msmarco-distilbert-base-v3': {\n",
    "        'base_repo': 'sentence-transformers',\n",
    "        'similarity': 'cosine'\n",
    "    },\n",
    "    'msmarco-roberta-base-v3': {\n",
    "        'base_repo': 'sentence-transformers',\n",
    "        'similarity': 'cosine'\n",
    "    },\n",
    "    'msmarco-distilbert-base-tas-b': {\n",
    "        'base_repo': 'sebastian-hofstaetter',\n",
    "        'similarity': 'dot'\n",
    "    },\n",
    "    'msmarco-roberta-base-ance-firstp': {\n",
    "        'base_repo': 'sentence-transformers',\n",
    "        'similarity': 'dot'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e00adbd-5248-49a7-ab6c-f080728f5fe2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2c2da173a6c4cc6b523d913d982adf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Select an Embedding Model:', layout=Layout(width='max-content'), options=('msmarco-disti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dropdown to select model\n",
    "select_model = widgets.Dropdown(\n",
    "    options = model_options.keys(),\n",
    "    layout = {'width':'max-content'},\n",
    "    style = {'description_width': 'max-content'},\n",
    "    description = 'Select an Embedding Model:'\n",
    ")\n",
    "\n",
    "# Display the dropdown widget\n",
    "display(select_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d10074d-1e6e-4f22-b4b6-ec4ac8224d86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded msmarco-distilbert-base-v4. Inference performed on cpu.\n"
     ]
    }
   ],
   "source": [
    "# Freeze the selected model for the rest of the notebook\n",
    "selected_model = select_model.value\n",
    "\n",
    "# Select device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Load the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(f'{model_options[selected_model][\"base_repo\"]}/{selected_model}')\n",
    "model = SentenceTransformer(f'{model_options[selected_model][\"base_repo\"]}/{selected_model}', device=device)\n",
    "print(f'Loaded {selected_model}. Inference performed on {device}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40902b0f-95d5-408c-93ee-2c9765bd5a7c",
   "metadata": {},
   "source": [
    "# Process Documents\n",
    "Chunk the documents, convert chunks into embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0ad1b43-f318-4792-a9fe-a39fa50fb687",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "425e507922ba41daa7f1000d709df08a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=100, continuous_update=False, description='chunk_size:', max=500, min=50, step=5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f339a87bb0c45af82dddb7025c8b853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=10, continuous_update=False, description='chunk_overlap:', max=50, min=5, step=5, style=Slider…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Chunking parameter sliders\n",
    "chunk_size_slider = widgets.IntSlider(\n",
    "    value=100,\n",
    "    min=50,\n",
    "    max=500,\n",
    "    step=5,\n",
    "    description='chunk_size:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "chunk_overlap_slider = widgets.IntSlider(\n",
    "    value=10,\n",
    "    min=5,\n",
    "    max=50,\n",
    "    step=5,\n",
    "    description='chunk_overlap:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d',\n",
    "    style={'description_width': 'max-content'}\n",
    ")\n",
    "\n",
    "# Display sliders\n",
    "display(chunk_size_slider)\n",
    "display(chunk_overlap_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93e90bde-0101-4884-b4e8-a74ed1cb8d22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lists for data\n",
    "docs_sources = []\n",
    "docs_chunks = []\n",
    "\n",
    "# Split multi-sentence lines into multiple lines (RecursiveTextSplitter assumption)\n",
    "for doc in docs:\n",
    "    docs[doc]['sent_split'] = '\\n'.join(nltk.tokenize.sent_tokenize(docs[doc]['raw']))\n",
    "\n",
    "# Chunk the documents\n",
    "logging.getLogger('transformers.tokenization_utils_base').setLevel(logging.ERROR)\n",
    "splitter = langchain.text_splitter.RecursiveCharacterTextSplitter(\n",
    "    chunk_size = chunk_size_slider.value,\n",
    "    chunk_overlap = chunk_overlap_slider.value,\n",
    "    length_function = lambda s: len(tokenizer(s)['input_ids'])\n",
    ")\n",
    "for doc in docs:\n",
    "    chunk_texts = [d.page_content for d in splitter.create_documents([docs[doc]['sent_split']])]\n",
    "    docs_chunks += chunk_texts\n",
    "    docs_sources += [doc] * len(chunk_texts)\n",
    "logging.getLogger('transformers.tokenization_utils_base').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c9ee798-5326-4066-bcb6-5cf38497fab9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc0e7e8cb2a4d8bb81992138fb3cb1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embedding chunks:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.7 s, sys: 3.47 s, total: 36.1 s\n",
      "Wall time: 37.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Function for batching\n",
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]\n",
    "\n",
    "# Generate embeddings for the chunks\n",
    "bsize = 32\n",
    "docs_embeddings_list = []\n",
    "for chunk_batch in tqdm(batch(docs_chunks, bsize), desc='Embedding chunks', total=(len(docs_chunks) // bsize + 1)):\n",
    "    docs_embeddings_list.append(model.encode(chunk_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "876175c7-fa7a-42d9-a0f8-6afe49aac082",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert embeddings list to a numpy array\n",
    "docs_embeddings = torch.from_numpy(np.vstack(docs_embeddings_list)).to(device)\n",
    "docs_embeddings_norm = docs_embeddings / docs_embeddings.norm(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c8b203-3a2c-48b3-a964-93a0c6ba2df5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Indexing\n",
    "\n",
    "Load the chunks into searchable data structures. In a production environments, these data structures would be replaced by Elasticsearch, Opensearch, or alternative vector search indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3ffda35-9976-415d-8d2d-8df423f93600",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Double check conversion\n",
    "assert len(docs_sources) == len(docs_chunks)\n",
    "assert docs_embeddings.shape[0] == len(docs_sources)\n",
    "\n",
    "# Search \n",
    "def search(query, res_count=5):\n",
    "    # Embed the query\n",
    "    q_embed = torch.from_numpy(model.encode([query])[0]).to(device)\n",
    "    \n",
    "    # Compute dot\n",
    "    if model_options[selected_model]['similarity'] == 'dot':\n",
    "        similarities = docs_embeddings @ q_embed\n",
    "    elif model_options[selected_model]['similarity'] == 'cosine':\n",
    "        similarities = docs_embeddings_norm @ (q_embed / q_embed.norm(dim=0))\n",
    "        \n",
    "    # Get top indices\n",
    "    values, indices = torch.topk(similarities, res_count)\n",
    "    indices = indices[torch.argsort(values, descending=True)]\n",
    "    \n",
    "    # Fetch results\n",
    "    return {\n",
    "        'sources': [docs_sources[i] for i in indices],\n",
    "        'chunks': [docs_chunks[i] for i in indices],\n",
    "        'similarities': similarities[indices]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a2437b-cd41-4594-b4c0-b271c7e9c42e",
   "metadata": {},
   "source": [
    "# Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e55b04a2-40d6-4e23-9963-a243ddab4b17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed13fc0241c4612bcbedba5b0cc8a39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Search')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4067c7782f2c4fd88055d30383697c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define fields\n",
    "search_bar = widgets.Text(placeholder='Search')\n",
    "results_field = widgets.Output()\n",
    "\n",
    "# Display fields\n",
    "display(search_bar)\n",
    "display(results_field)\n",
    "\n",
    "# Define the search function\n",
    "def handle_search(query):\n",
    "    results_field.clear_output()\n",
    "    if query:\n",
    "        # Launch search against elasticsearch\n",
    "        start = time.time()\n",
    "        res = search(query)\n",
    "        end = time.time()\n",
    "        \n",
    "        # Output the results\n",
    "        with results_field:\n",
    "            print(f'Search time: {end - start:.2f}s\\n')\n",
    "            for i, chunk in enumerate(res['chunks']):\n",
    "                print(f'Source: {res[\"sources\"][i]} ({res[\"similarities\"][i]:.4f})')\n",
    "                print(f'------------------\\n{chunk}\\n')\n",
    "        \n",
    "# Register the search function to execute on submit\n",
    "def handle_submit(sender):\n",
    "    handle_search(search_bar.value)\n",
    "search_bar.continuous_update = False\n",
    "search_bar.observe(handle_submit, 'value')"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

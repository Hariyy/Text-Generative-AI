{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b50760f7-87ed-42dd-9699-41b05fd8fbd8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 61.9 ms, sys: 72.7 ms, total: 135 ms\n",
      "Wall time: 13.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "! pip install -qq -U langchain tiktoken pypdf chromadb faiss-gpu\n",
    "! pip install -qq -U transformers InstructorEmbedding sentence_transformers\n",
    "! pip install -qq -U accelerate bitsandbytes xformers einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87d7655b-aaf9-4b1e-89e2-8c328dd802d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyopenssl in /home/sagemaker-user/.local/lib/python3.9/site-packages (23.2.0)\n",
      "Requirement already satisfied: cryptography!=40.0.0,!=40.0.1,<42,>=38.0.0 in /home/sagemaker-user/.local/lib/python3.9/site-packages (from pyopenssl) (41.0.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.9/site-packages (from cryptography!=40.0.0,!=40.0.1,<42,>=38.0.0->pyopenssl) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.9/site-packages (from cffi>=1.12->cryptography!=40.0.0,!=40.0.1,<42,>=38.0.0->pyopenssl) (2.21)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyopenssl --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9fe1c65-a250-4d06-b8dd-1790f5f2064e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install --no-cache fastapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ba04ac9-4689-41eb-aa64-18576c65b9b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install typing-inspect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccaf2006-322f-4671-aef5-6c571bee680c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install typing-extensions==4.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "541c8ce7-0173-4a73-9c7a-019b20205137",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install typing_extensions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1272882-d746-473c-973c-3ed09921c4b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a144f0f-298c-4466-b6dc-ecfe129a40b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install langchain --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bab5f2f9-801a-4124-a59c-3f1379c3a9f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip -q install langchain==0.0.018\n",
    "# !pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86e7789c-f435-49e3-8328-55e2ad871a59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install pydantic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93cffd7a-45be-4ff3-a183-55433f912d05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c012802-c906-479f-9aa6-2abd6205396f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.230\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import textwrap\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline,LlamaTokenizer,BitsAndBytesConfig\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "import torch\n",
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62848f2a-924d-4f55-892a-fa41babe9d67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = UnstructuredPDFLoader(\"story.pdf\")\n",
    "transcript = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e9d5bf4-0d53-488e-9585-113a54bbe035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## SPLIT THE PDF FILE#####\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=50)\n",
    "texts = text_splitter.split_documents(transcript) \n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bd926ad-5e3b-425b-9cc4-3186cc8df8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Embedding and convert chunks to Vectordb using chroma##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c111e28d-d5c6-421c-9c87-cc4bd630537e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "CPU times: user 3min 20s, sys: 1min 17s, total: 4min 37s\n",
      "Wall time: 23.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### this takes ~35 min to run\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "persist_directory = 'story'\n",
    "\n",
    "### download embeddings model\n",
    "instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\")\n",
    "\n",
    "### create embeddings and DB\n",
    "vectordb = Chroma.from_documents(documents=texts,\n",
    "                                 embedding=instructor_embeddings,\n",
    "                                 persist_directory=persist_directory\n",
    "                                )\n",
    "\n",
    "\n",
    "\n",
    "### persist Chroma database\n",
    "vectordb.persist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0bf4e73-4b6f-49cf-9cbc-a19b57f15fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "load_directory = 'story'\n",
    "\n",
    "### download embeddings model\n",
    "instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\"\n",
    "                                                     )\n",
    "\n",
    "vectordb = Chroma(persist_directory=load_directory, embedding_function=instructor_embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf42d6d9-fe71-4b9e-a1e6-dcf63bff7a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use falcon LLM model or any other model##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f19677cd-7ecd-4c77-81f9-e152ca2c9339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d1d967b4054d698d18ff823aaa4b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quantization_config = BitsAndBytesConfig(llm_int8_threshold=200.0)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"h2oai/h2ogpt-gm-oasst1-en-2048-falcon-7b-v2\")\n",
    "        \n",
    "model = AutoModelForCausalLM.from_pretrained(\"h2oai/h2ogpt-gm-oasst1-en-2048-falcon-7b-v2\",\n",
    "                                                     load_in_8bit=True,\n",
    "                                                     device_map='auto',\n",
    "                                                     torch_dtype=torch.bfloat16,\n",
    "                                                     low_cpu_mem_usage=True,\n",
    "                                                     trust_remote_code=True,\n",
    "                                                     quantization_config=quantization_config\n",
    "                                                    )\n",
    "max_len = 4098\n",
    "task = \"text-generation\"\n",
    "T = 0     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54ebd74b-a4d1-49ea-afad-da581b7f42e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pass llm model into the huggingface Pipeline###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7d3fa51-24a6-4264-9d40-47d338a782f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'RWForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\n",
    "    task=task,\n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    max_length=max_len,\n",
    "    temperature=T,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.15\n",
    ")\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e5e3abd-d462-4861-9897-9439b8c85259",
   "metadata": {},
   "outputs": [],
   "source": [
    "## pass full pipeline into the QA chain####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49f3f244-09f5-4e9e-a89e-9f937a5f1b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 3, \"search_type\" : \"similarity\"})\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                       chain_type=\"stuff\", \n",
    "                                       retriever=retriever, \n",
    "                                       return_source_documents=True,\n",
    "                                       verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44a0d509-2e40-4cbc-a9da-1f4ab247f41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def final_text(text, width=300):\n",
    "    lines = text.split('\\n')\n",
    "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
    "    wrapped_text = '\\n'.join(wrapped_lines)\n",
    "    return wrapped_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42da69bd-faad-4588-a99a-fdf8512ea543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_llm_response(llm_final_response):\n",
    "    print(final_text(llm_final_response['result']))\n",
    "\n",
    "def final_answer(question):\n",
    "    llm_final_response = qa_chain(question)\n",
    "    answer = final_llm_response(llm_final_response)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981131a6-6ba9-46ff-a4ef-677d889e3f7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "question = \"When was the first day of Donna's holiday?\"\n",
    "final_answer(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9334189d-cf71-41be-ad4a-0fe81447d03a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.16xlarge",
  "kernelspec": {
   "display_name": "Python 3 (adl-core-sagemaker-image/5)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:110008799848:image-version/adl-core-sagemaker-image/5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

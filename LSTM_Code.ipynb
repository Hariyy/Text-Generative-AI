{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 models for Intents with & without Over sampling(SMOTE)- Taken >50 count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cspro_primary_topic</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DB - Payments</td>\n",
       "      <td>agent hello craig tom hey thanks hey something...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HW - Annual Enrollment</td>\n",
       "      <td>agent good morning thank calling eighteen bene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HW - Annual Enrollment</td>\n",
       "      <td>agent good morning thank calling teensy benefi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CM - Access</td>\n",
       "      <td>agent thank calling chancy dennis center name ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HW - Annual Enrollment</td>\n",
       "      <td>agent moment please call ahead customer hey ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cspro_primary_topic                                         transcript\n",
       "0           DB - Payments  agent hello craig tom hey thanks hey something...\n",
       "1  HW - Annual Enrollment  agent good morning thank calling eighteen bene...\n",
       "2  HW - Annual Enrollment  agent good morning thank calling teensy benefi...\n",
       "3             CM - Access  agent thank calling chancy dennis center name ...\n",
       "4  HW - Annual Enrollment  agent moment please call ahead customer hey ma..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('df_cleaned.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72559, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.drop_duplicates(subset='transcript')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "print(df.cspro_primary_topic.nunique())\n",
    "\n",
    "print((df.cspro_primary_topic.value_counts()>50).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71473, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df[df.groupby('cspro_primary_topic')['cspro_primary_topic'].transform('size') > 50]\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HW - Annual Enrollment            17109\n",
       "CM - Access                        8860\n",
       "HW - COBRA                         8260\n",
       "CM - External Referral             5300\n",
       "CM - Internal Warm Transfer        3712\n",
       "DB - Payments                      3219\n",
       "HRFS Call                          3210\n",
       "COBRA/Direct Billing               2961\n",
       "HW - Life Insurance                2210\n",
       "CM - Workflow                      1729\n",
       "Referral                           1652\n",
       "CM - LOA                           1604\n",
       "Payroll - Ongoing Processing       1126\n",
       "Qualified Status Change             962\n",
       "Time and Labor - PTO                915\n",
       "DC - Regular Withdrawals            902\n",
       "Payroll - Tax                       685\n",
       "DC - Rollover In                    653\n",
       "Data Issues                         646\n",
       "YSA - Web                           501\n",
       "YSA - Active HRA                    486\n",
       "PAY - Paycheck Assistance           380\n",
       "YSA - Commuter                      302\n",
       "CM - Case Management                282\n",
       "DB - Lump Sum Window                279\n",
       "CM - QDRO                           276\n",
       "General Plan Questions              274\n",
       "HW - Appeals                        271\n",
       "CM - Disability                     234\n",
       "DC - Reallocation/Transfer          200\n",
       "YSA - Tuition                       200\n",
       "Common                              191\n",
       "DC - Investment Elections           175\n",
       "Medicare                            170\n",
       "DBP                                 162\n",
       "myHR - ESS                          149\n",
       "HW - Medical Plans                  136\n",
       "WFA - Job and Comp Change           128\n",
       "Retiremnt Specialist - Inbound      121\n",
       "CM - OFS Only                       100\n",
       "PAY - LOA or Disability              93\n",
       "HW - Dental Plans                    92\n",
       "DC - Nonqualified                    81\n",
       "HR- Payroll-Ongoing Processing       76\n",
       "WFA - Personal Data Change           64\n",
       "CM - Manager Coaching                60\n",
       "SAP - HR                             59\n",
       "HW - Death                           56\n",
       "CM - Rehire                          55\n",
       "HW - Beneficiary                     53\n",
       "WFA - Job and Compensation           52\n",
       "Name: cspro_primary_topic, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.cspro_primary_topic.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "vocab_size = 50000\n",
    "max_length = 300\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "\n",
    "tokenizer = Tokenizer(num_words = vocab_size)\n",
    "tokenizer.fit_on_texts(df1['transcript'])\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agent': 1,\n",
       " 'customer': 2,\n",
       " 'okay': 3,\n",
       " 'redacted': 4,\n",
       " 'know': 5,\n",
       " 'thank': 6,\n",
       " 'call': 7,\n",
       " 'yes': 8,\n",
       " 'one': 9,\n",
       " 'get': 10}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(word_index.items())[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44154\n"
     ]
    }
   ],
   "source": [
    "print(len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df1['transcript'] = tokenizer.texts_to_sequences(df1['transcript'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent hello craig tom hey thanks hey something give call hey bye bye okay greatly okay okay okay thanks bye compression thank bye bye give quick quick schedule going hey okay thanks point okay thanks bye hello hey quickly thank thank bye call thank bye hey good hey okay hey bye thanks think calling call thank bye bye bye okay thank goodbye okay company working cleaning bye bye bye okay hey thanks okay thank bye thanks look customer please agent call thanks okay okay leaf okay bye hey thanks bye please conclude know bye okay bye okay speaking thank okay talk okay thanks okay call today okay thank bye okay thank bye okay okay thanks bye okay okay okay bye bye salmon time thank commander greg pickering one clock bye norman okay bye thanks bye claim calling customer okay okay\n",
      "[1, 53, 2142, 777, 90, 147, 90, 99, 28, 7, 90, 16, 16, 3, 2096, 3, 3, 3, 147, 16, 14056, 6, 16, 16, 28, 427, 427, 840, 50, 90, 3, 147, 306, 3, 147, 16, 53, 90, 1066, 6, 6, 16, 7, 6, 16, 90, 49, 90, 3, 90, 16, 147, 73, 31, 7, 6, 16, 16, 16, 3, 6, 722, 3, 169, 269, 1878, 16, 16, 16, 3, 90, 147, 3, 6, 16, 147, 82, 2, 17, 1, 7, 147, 3, 3, 1425, 3, 16, 90, 147, 16, 17, 3735, 5, 16, 3, 16, 3, 284, 6, 3, 123, 3, 147, 3, 7, 58, 3, 6, 16, 3, 6, 16, 3, 3, 147, 16, 3, 3, 3, 16, 16, 5405, 35, 6, 6407, 1448, 18821, 9, 646, 16, 2423, 3, 16, 147, 16, 228, 31, 2, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "print(df['transcript'][0])\n",
    "print(df1['transcript'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= pad_sequences(df1['transcript'], maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     1,    53,\n",
       "        2142,   777,    90,   147,    90,    99,    28,     7,    90,\n",
       "          16,    16,     3,  2096,     3,     3,     3,   147,    16,\n",
       "       14056,     6,    16,    16,    28,   427,   427,   840,    50,\n",
       "          90,     3,   147,   306,     3,   147,    16,    53,    90,\n",
       "        1066,     6,     6,    16,     7,     6,    16,    90,    49,\n",
       "          90,     3,    90,    16,   147,    73,    31,     7,     6,\n",
       "          16,    16,    16,     3,     6,   722,     3,   169,   269,\n",
       "        1878,    16,    16,    16,     3,    90,   147,     3,     6,\n",
       "          16,   147,    82,     2,    17,     1,     7,   147,     3,\n",
       "           3,  1425,     3,    16,    90,   147,    16,    17,  3735,\n",
       "           5,    16,     3,    16,     3,   284,     6,     3,   123,\n",
       "           3,   147,     3,     7,    58,     3,     6,    16,     3,\n",
       "           6,    16,     3,     3,   147,    16,     3,     3,     3,\n",
       "          16,    16,  5405,    35,     6,  6407,  1448, 18821,     9,\n",
       "         646,    16,  2423,     3,    16,   147,    16,   228,    31,\n",
       "           2,     3,     3], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n",
      "300\n",
      "329\n",
      "300\n",
      "342\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(df1['transcript'][0]))\n",
    "print(len(X[0]))\n",
    "\n",
    "print(len(df1['transcript'][1]))\n",
    "print(len(X[1]))\n",
    "\n",
    "print(len(df1['transcript'][10]))\n",
    "print(len(X[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df1['cspro_primary_topic'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "y = LabelEncoder().fit_transform(y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71473,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split of data without sampling\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57178, 300) (57178,)\n",
      "(14295, 300) (14295,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://artifactory.alight.com/artifactory/api/pypi/python-pypi-remote/simple\n",
      "Collecting imblearn\n",
      "  Using cached https://artifactory.alight.com/artifactory/api/pypi/python-pypi-remote/packages/packages/81/a7/4179e6ebfd654bd0eac0b9c06125b8b4c96a9d0a8ff9e9507eb2a26d2d7e/imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Using cached https://artifactory.alight.com/artifactory/api/pypi/python-pypi-remote/packages/packages/80/98/dc784205a7e3034e84d41ac4781660c67ad6327f2f5a80c568df31673d1c/imbalanced_learn-0.8.0-py3-none-any.whl (206 kB)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (1.2.2)\n",
      "Collecting scikit-learn>=0.24\n",
      "  Using cached https://artifactory.alight.com/artifactory/api/pypi/python-pypi-remote/packages/packages/d3/eb/d0e658465c029feb7083139d9ead51000742e88b1fb7f1504e19e1b4ce6e/scikit_learn-0.24.2-cp36-cp36m-manylinux2010_x86_64.whl (22.2 MB)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (1.18.5)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached https://artifactory.alight.com/artifactory/api/pypi/python-pypi-remote/packages/packages/c6/e8/c216b9b60cbba4642d3ca1bae7a53daa0c24426f662e0e3ce3dc7f6caeaa/threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: threadpoolctl, scikit-learn, imbalanced-learn, imblearn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.22\n",
      "    Uninstalling scikit-learn-0.22:\n",
      "      Successfully uninstalled scikit-learn-0.22\n",
      "Successfully installed imbalanced-learn-0.8.0 imblearn-0.0 scikit-learn-0.24.2 threadpoolctl-2.2.0\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.6 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn --index-url https://artifactory.alight.com/artifactory/api/pypi/python-pypi-remote/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "Xs, ys = sm.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0, 17109],\n",
       "       [    1, 17109],\n",
       "       [    2, 17109],\n",
       "       [    3, 17109],\n",
       "       [    4, 17109],\n",
       "       [    5, 17109],\n",
       "       [    6, 17109],\n",
       "       [    7, 17109],\n",
       "       [    8, 17109],\n",
       "       [    9, 17109],\n",
       "       [   10, 17109],\n",
       "       [   11, 17109],\n",
       "       [   12, 17109],\n",
       "       [   13, 17109],\n",
       "       [   14, 17109],\n",
       "       [   15, 17109],\n",
       "       [   16, 17109],\n",
       "       [   17, 17109],\n",
       "       [   18, 17109],\n",
       "       [   19, 17109],\n",
       "       [   20, 17109],\n",
       "       [   21, 17109],\n",
       "       [   22, 17109],\n",
       "       [   23, 17109],\n",
       "       [   24, 17109],\n",
       "       [   25, 17109],\n",
       "       [   26, 17109],\n",
       "       [   27, 17109],\n",
       "       [   28, 17109],\n",
       "       [   29, 17109],\n",
       "       [   30, 17109],\n",
       "       [   31, 17109],\n",
       "       [   32, 17109],\n",
       "       [   33, 17109],\n",
       "       [   34, 17109],\n",
       "       [   35, 17109],\n",
       "       [   36, 17109],\n",
       "       [   37, 17109],\n",
       "       [   38, 17109],\n",
       "       [   39, 17109],\n",
       "       [   40, 17109],\n",
       "       [   41, 17109],\n",
       "       [   42, 17109],\n",
       "       [   43, 17109],\n",
       "       [   44, 17109],\n",
       "       [   45, 17109],\n",
       "       [   46, 17109],\n",
       "       [   47, 17109],\n",
       "       [   48, 17109],\n",
       "       [   49, 17109],\n",
       "       [   50, 17109]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "unique1, counts1 = np.unique(ys, return_counts=True)\n",
    "\n",
    "np.asarray((unique1, counts1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split of over-sampled data\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(Xs, ys, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 628242 samples, validate on 69805 samples\n",
      "Epoch 1/50\n",
      "628242/628242 [==============================] - 3637s 6ms/sample - loss: 3.2964 - accuracy: 0.1824 - val_loss: 2.7850 - val_accuracy: 0.3083\n",
      "Epoch 2/50\n",
      "628242/628242 [==============================] - 3659s 6ms/sample - loss: 2.7456 - accuracy: 0.3175 - val_loss: 2.4973 - val_accuracy: 0.3794\n",
      "Epoch 3/50\n",
      "628242/628242 [==============================] - 3638s 6ms/sample - loss: 2.5725 - accuracy: 0.3575 - val_loss: 2.3500 - val_accuracy: 0.4136\n",
      "Epoch 4/50\n",
      "628242/628242 [==============================] - 3648s 6ms/sample - loss: 2.4671 - accuracy: 0.3838 - val_loss: 2.2770 - val_accuracy: 0.4316\n",
      "Epoch 5/50\n",
      "628242/628242 [==============================] - 3811s 6ms/sample - loss: 2.3981 - accuracy: 0.3998 - val_loss: 2.2124 - val_accuracy: 0.4459\n",
      "Epoch 6/50\n",
      "628242/628242 [==============================] - 3807s 6ms/sample - loss: 2.3468 - accuracy: 0.4107 - val_loss: 2.1809 - val_accuracy: 0.4544\n",
      "Epoch 7/50\n",
      "628242/628242 [==============================] - 3804s 6ms/sample - loss: 2.3041 - accuracy: 0.4194 - val_loss: 2.1478 - val_accuracy: 0.4615\n",
      "Epoch 8/50\n",
      "213120/628242 [=========>....................] - ETA: 41:13 - loss: 2.2605 - accuracy: 0.4299"
     ]
    }
   ],
   "source": [
    "#Model with over sampled data\n",
    "\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "\n",
    "embedding_dim=100\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(vocab_size,embedding_dim,input_length = X.shape[1]))\n",
    "model1.add(SpatialDropout1D(0.2))\n",
    "model1.add(LSTM(100,dropout = 0.2, recurrent_dropout = 0.2))\n",
    "model1.add(Dense(98,activation = \"softmax\"))\n",
    "model1.compile(loss = \"sparse_categorical_crossentropy\",optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "\n",
    "EPOCHS = 50\n",
    "batch_size = 64\n",
    "\n",
    "history1 = model1.fit(X_train1,y_train1, epochs = EPOCHS,batch_size = batch_size,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 51460 samples, validate on 5718 samples\n",
      "Epoch 1/50\n",
      "51460/51460 [==============================] - 314s 6ms/sample - loss: 2.7696 - accuracy: 0.2551 - val_loss: 2.5387 - val_accuracy: 0.3171\n",
      "Epoch 2/50\n",
      "51460/51460 [==============================] - 311s 6ms/sample - loss: 2.2964 - accuracy: 0.3822 - val_loss: 2.0497 - val_accuracy: 0.4598\n",
      "Epoch 3/50\n",
      "51460/51460 [==============================] - 311s 6ms/sample - loss: 1.9432 - accuracy: 0.4772 - val_loss: 1.8600 - val_accuracy: 0.4951\n",
      "Epoch 4/50\n",
      "51460/51460 [==============================] - 311s 6ms/sample - loss: 1.7220 - accuracy: 0.5267 - val_loss: 1.6952 - val_accuracy: 0.5421\n",
      "Epoch 5/50\n",
      "51460/51460 [==============================] - 311s 6ms/sample - loss: 1.5505 - accuracy: 0.5712 - val_loss: 1.6091 - val_accuracy: 0.5624\n",
      "Epoch 6/50\n",
      "51460/51460 [==============================] - 311s 6ms/sample - loss: 1.4095 - accuracy: 0.6038 - val_loss: 1.5741 - val_accuracy: 0.5654\n",
      "Epoch 7/50\n",
      "51460/51460 [==============================] - 312s 6ms/sample - loss: 1.2758 - accuracy: 0.6396 - val_loss: 1.5710 - val_accuracy: 0.5642\n",
      "Epoch 8/50\n",
      "51460/51460 [==============================] - 312s 6ms/sample - loss: 1.1441 - accuracy: 0.6780 - val_loss: 1.5745 - val_accuracy: 0.5661\n",
      "Epoch 9/50\n",
      "51460/51460 [==============================] - 311s 6ms/sample - loss: 1.0229 - accuracy: 0.7107 - val_loss: 1.6154 - val_accuracy: 0.5661\n",
      "Epoch 10/50\n",
      "51460/51460 [==============================] - 311s 6ms/sample - loss: 0.9040 - accuracy: 0.7456 - val_loss: 1.6925 - val_accuracy: 0.5598\n",
      "Epoch 11/50\n",
      "51460/51460 [==============================] - 311s 6ms/sample - loss: 0.8014 - accuracy: 0.7718 - val_loss: 1.7708 - val_accuracy: 0.5567\n",
      "Epoch 12/50\n",
      "51460/51460 [==============================] - 312s 6ms/sample - loss: 0.7081 - accuracy: 0.8010 - val_loss: 1.8453 - val_accuracy: 0.5476\n",
      "Epoch 13/50\n",
      "51460/51460 [==============================] - 311s 6ms/sample - loss: 0.6262 - accuracy: 0.8236 - val_loss: 1.9449 - val_accuracy: 0.5427\n",
      "Epoch 14/50\n",
      "51460/51460 [==============================] - 311s 6ms/sample - loss: 0.5522 - accuracy: 0.8423 - val_loss: 2.0477 - val_accuracy: 0.5283\n",
      "Epoch 15/50\n",
      "51460/51460 [==============================] - 312s 6ms/sample - loss: 0.4906 - accuracy: 0.8596 - val_loss: 2.1712 - val_accuracy: 0.5304\n",
      "Epoch 16/50\n",
      "51460/51460 [==============================] - 314s 6ms/sample - loss: 0.4369 - accuracy: 0.8745 - val_loss: 2.2492 - val_accuracy: 0.5261\n",
      "Epoch 17/50\n",
      "51460/51460 [==============================] - 312s 6ms/sample - loss: 0.3868 - accuracy: 0.8891 - val_loss: 2.3818 - val_accuracy: 0.5210\n",
      "Epoch 18/50\n",
      "51460/51460 [==============================] - 314s 6ms/sample - loss: 0.3487 - accuracy: 0.8992 - val_loss: 2.4757 - val_accuracy: 0.5185\n",
      "Epoch 19/50\n",
      "51460/51460 [==============================] - 313s 6ms/sample - loss: 0.3092 - accuracy: 0.9111 - val_loss: 2.5878 - val_accuracy: 0.5143\n",
      "Epoch 20/50\n",
      "51460/51460 [==============================] - 312s 6ms/sample - loss: 0.2814 - accuracy: 0.9185 - val_loss: 2.6968 - val_accuracy: 0.5052\n",
      "Epoch 21/50\n",
      "51460/51460 [==============================] - 312s 6ms/sample - loss: 0.2528 - accuracy: 0.9276 - val_loss: 2.7493 - val_accuracy: 0.5114\n",
      "Epoch 22/50\n",
      "51460/51460 [==============================] - 316s 6ms/sample - loss: 0.2307 - accuracy: 0.9326 - val_loss: 2.8425 - val_accuracy: 0.4974\n",
      "Epoch 23/50\n",
      "51460/51460 [==============================] - 316s 6ms/sample - loss: 0.2050 - accuracy: 0.9420 - val_loss: 2.9345 - val_accuracy: 0.4955\n",
      "Epoch 24/50\n",
      "51460/51460 [==============================] - 318s 6ms/sample - loss: 0.1886 - accuracy: 0.9457 - val_loss: 3.0080 - val_accuracy: 0.4991\n",
      "Epoch 25/50\n",
      "51460/51460 [==============================] - 313s 6ms/sample - loss: 0.1695 - accuracy: 0.9507 - val_loss: 3.1094 - val_accuracy: 0.4963\n",
      "Epoch 26/50\n",
      "51460/51460 [==============================] - 316s 6ms/sample - loss: 0.1543 - accuracy: 0.9556 - val_loss: 3.2267 - val_accuracy: 0.4965\n",
      "Epoch 27/50\n",
      "51460/51460 [==============================] - 316s 6ms/sample - loss: 0.1458 - accuracy: 0.9575 - val_loss: 3.2646 - val_accuracy: 0.4907\n",
      "Epoch 28/50\n",
      "51460/51460 [==============================] - 319s 6ms/sample - loss: 0.1331 - accuracy: 0.9603 - val_loss: 3.3270 - val_accuracy: 0.4885\n",
      "Epoch 29/50\n",
      "26688/51460 [==============>...............] - ETA: 2:30 - loss: 0.1135 - accuracy: 0.9674"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-46aa542a9664>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Model without over sampled data\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "embedding_dim=100\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size,embedding_dim,input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100,dropout = 0.2, recurrent_dropout = 0.2))\n",
    "model.add(Dense(98,activation = \"softmax\"))\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\",optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "\n",
    "EPOCHS = 50\n",
    "batch_size = 64\n",
    "\n",
    "history = model.fit(X_train,y_train, epochs = EPOCHS,batch_size = batch_size,validation_split=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.1 Python 3.6 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.1-gpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
